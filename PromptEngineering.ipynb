{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "ML_template = '''I want you to act as a Machine Learning Scientist which advices the people.In an easy way, explain the basics of {machine_learning_concept}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['machine_learning_concept'],\n",
    "    template=ML_template,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to act as a Machine Learning Scientist which advices the people.In an easy way, explain the basics of Linear Regression.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(machine_learning_concept='Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "llm = Ollama(base_url = 'http://localhost:11434', model = \"llama2\",temperature=0.6)\n",
    "chain1 = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHello there! As a Machine Learning Scientist, I\\'d be happy to help you understand the basics of the Vision Transformer (ViT) architecture. ViT is a type of neural network designed specifically for image classification tasks, and it has gained significant attention in the field of computer vision due to its impressive performance on various benchmark datasets.\\n\\nSo, what is ViT? In simple terms, ViT is a neural network that uses a transformer architecture to process visual data, such as images. The transformer architecture was originally developed for natural language processing tasks, and it has proven to be highly effective at processing sequential data. ViT applies this same architecture to images, which are naturally 2D and can be thought of as sequences of pixels.\\n\\nHere\\'s how ViT works:\\n\\n1. **Image Representation**: The first step in the ViT process is to represent an image as a sequence of non-overlapping patches. These patches are typically rectangular in shape and are arranged in a grid-like fashion. Each patch represents a small portion of the original image.\\n2. **Positional Encoding**: To preserve the spatial information of the image, ViT applies positional encoding to each patch. Positional encoding is a technique that adds context to the patches by including information about their positions in the image. This allows the network to understand how different parts of the image are related to each other.\\n3. **Multi-Head Self-Attention**: Once the patches have been encoded, ViT applies a multi-head self-attention mechanism to them. This allows the network to learn the dependencies between different patches and to capture complex contextual relationships in the image. In essence, self-attention allows the network to \"attend\" to different parts of the image simultaneously and weigh their importance.\\n4. **Feed Forward Network**: After the self-attention mechanism, the output is passed through a feed forward network (FFN). The FFN consists of multiple layers of linear transformation followed by a non-linear activation function. This allows the network to learn more complex patterns in the image and to make predictions about the class label.\\n5. **Classification**: Finally, the output of the FFN is passed through a classification head, which produces the final output of the network. The classification head consists of a softmax activation function that outputs a probability distribution over the possible class labels.\\n\\nNow, here are some key advantages of ViT:\\n\\n* **Global Understanding**: Unlike traditional convolutional neural networks (CNNs), which only consider local information in small regions of an image, ViT can capture global context and relationships between different parts of the image. This allows it to perform better on tasks that require a deeper understanding of the image as a whole.\\n* **Efficiency**: Because ViT does not rely on convolutional layers, it requires fewer parameters and computations compared to CNNs. This makes it more efficient in terms of both computational resources and memory usage.\\n* **Flexibility**: ViT can be easily adapted to different image classification tasks by changing the number of patches used or the size of each patch. This flexibility makes it a promising architecture for a wide range of applications.\\n\\nIn summary, ViT is a transformer-based neural network architecture that processes images as sequences of patches and uses self-attention to capture complex contextual relationships. Its advantages include its ability to capture global understanding, efficiency, and flexibility, making it a promising approach for image classification tasks.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.run(\"Vision Transformer architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In an easy way translate the following sentence Hello how are you ? to Hindi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Language Translation\n",
    "from langchain import PromptTemplate\n",
    "template = '''In an easy way translate the following sentence {sentence} to {target_language}'''\n",
    "language_prompt = PromptTemplate(\n",
    "    input_variables=['sentence','target_language'],\n",
    "    template=template\n",
    ")\n",
    "language_prompt.format(sentence=\"Hello how are you ?\",target_language=\"Hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello How are you',\n",
       " 'target_language': 'Kannada',\n",
       " 'text': '\\nCertainly! Here\\'s a simple translation of \"Hello, how are you?\" in Kannada:\\n\\n\"ಹುಡೊಂಬರ ಸಮಾಚಾರಿ?\" (Hudugumbare samacharaari?)\\n\\nHere\\'s a breakdown of the sentence:\\n\\n* \"ಹುಡೊಂಬರ\" (Hudugumbare) - Hello\\n* \"ಸಮಾಚಾರಿ\" (Samacharaari) - How are you?\\n\\nI hope this helps! Let me know if you have any other questions.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = LLMChain(llm=llm,prompt=language_prompt)\n",
    "chain2({'sentence':\"Hello How are you\",'target_language':\"Kannada\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
